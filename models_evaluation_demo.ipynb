{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yzzMBthEv3F5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pulearn import BaggingPuClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, make_scorer, average_precision_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# defined performance metrics scorers\n",
        "\n",
        "def auprc_score(y_true, y_pred):\n",
        "    return average_precision_score(y_true, y_pred)\n",
        "\n",
        "def topk(y_true, y_pred, top_k=100, get_mask=False):\n",
        "\n",
        "    sorted_indices = y_pred.argsort()[::-1]\n",
        "    top_k_indices = sorted_indices[:top_k]\n",
        "    y_pred_top_k_mask = np.full(y_true.shape, False, dtype=bool)\n",
        "    y_pred_top_k_mask[top_k_indices] = True\n",
        "    top_k_hits = y_true.values[y_pred_top_k_mask].sum()\n",
        "    \n",
        "    if get_mask == False:\n",
        "        return top_k_hits\n",
        "    else: \n",
        "        return y_pred_top_k_mask\n",
        "\n",
        "# define evaluation function\n",
        "\n",
        "def evaluate(model, test_X, test_y, scorers):\n",
        "    # Using a dictionary to store scores associated with each scorer's name\n",
        "    y_pred = model.predict_proba(test_X)[:,1]\n",
        "    scores = {name: [] for name, _, _ in scorers}\n",
        "\n",
        "    for name, scorer, scorer_args in scorers:\n",
        "        score = scorer(y_true=test_y, y_pred=y_pred, **scorer_args)\n",
        "        scores[name]=score\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_models(models, models_name, train_X, train_y, test_X, test_y, scorers_with_args, eval_models_path, eval_results_path):\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for model in models:\n",
        "        model.fit(train_X, train_y)\n",
        "\n",
        "    eval_models_file_name = models_name + '.pickle'\n",
        "    eval_models_file_path = os.path.join(eval_models_path, eval_models_file_name)\n",
        "\n",
        "    with open(eval_models_file_path, 'wb') as f:\n",
        "        pickle.dump(models, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    for model in models:\n",
        "        result_for_a_model = evaluate(model, test_X, test_y, scorers_with_args)\n",
        "        print(result_for_a_model)\n",
        "        results.append(result_for_a_model)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    eval_results_file_name = 'eval_result_' + models_name + '.csv'\n",
        "    eval_results_file_path = os.path.join(eval_results_path, eval_results_file_name)\n",
        "\n",
        "    results_df.to_csv(eval_results_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_avg_feature_importances (models):\n",
        "# Iterate all random forest models in the model list. From each random forest, obtain the feature importance from all its tree. \n",
        "# Average the feature importance of each random forest model, and then average the importance of all random forest models\n",
        "# Finally, plot the average importance of each feature vector\n",
        "\n",
        "    all_rf_importances = []\n",
        "\n",
        "    for idx, model in enumerate(models):\n",
        "        clf = model.named_steps['clf']\n",
        "        feature_importances = [estimator.feature_importances_ for estimator in clf.estimators_]\n",
        "        df_feature_importances = pd.DataFrame(feature_importances)\n",
        "        feature_importances_means = df_feature_importances.mean()\n",
        "        all_rf_importances.append(feature_importances_means)\n",
        "\n",
        "    # Convert list of feature importances to a DataFrame\n",
        "    df_all_rf_importances = pd.concat(all_rf_importances, axis=1).T\n",
        "\n",
        "    # Calculate the mean feature importance across all models\n",
        "    average_importance = df_all_rf_importances.mean()\n",
        "\n",
        "    # Sort by descending importance\n",
        "    sorted_means = average_importance.sort_values(ascending=False)\n",
        "    \n",
        "    return sorted_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate Candidate PU Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_states be used:  [20, 35, 45, 59, 3, 96, 84, 3, 23, 55, 22, 89, 67, 71, 67, 57, 1, 14, 36, 93, 85, 83, 96, 74, 36]\n"
          ]
        }
      ],
      "source": [
        "# evaluation of candidates models by repeating 25 rounds of testing by different random seeds\n",
        "\n",
        "eva_rounds = 25\n",
        "\n",
        "np.random.seed(44)\n",
        "random_states = [np.random.randint(0, 99) for _ in range(eva_rounds)]\n",
        "print(\"random_states be used: \", random_states)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# configure scorers and parameters \n",
        "scorers_with_args = [\n",
        "    ('top_20', topk, {'top_k': 20}),\n",
        "    ('top_100', topk, {'top_k': 100}),\n",
        "    ('auprc', auprc_score, {})\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_models_path = os.path.join('eval_models')\n",
        "eval_results_path = os.path.join('eval_results')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading the dataset (d=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load datasets\n",
        "\n",
        "dataset_filename = 'dataset_p_4_q_1_dim_128_walkleng_100_numwalks_500_seed_37.csv'\n",
        "\n",
        "file_path = os.path.join('data', 'datasets', dataset_filename)\n",
        "dataset = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset shape, X: (12968, 128)\n",
            "Training dataset shape, y: (12968,)\n",
            "Testing dataset shape, X: (3242, 128)\n",
            "Testing dataset shape, y: (3242,)\n"
          ]
        }
      ],
      "source": [
        "# X is the data of feature1 to feature128 in the dataset\n",
        "X = dataset.drop(['id', 'y'], axis=1)\n",
        "# y is the target value of the last column in the dataset\n",
        "y = dataset['y']\n",
        "\n",
        "# split the dataset into training and testing with 80% to 20% proportion and randomly shuffle the data\n",
        "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.2, random_state=37,stratify=y)\n",
        "\n",
        "train_indices = train_X.index\n",
        "test_indices = test_X.index\n",
        "\n",
        "# print the shape of the data\n",
        "print(f'Training dataset shape, X: {train_X.shape}')\n",
        "print(f'Training dataset shape, y: {train_y.shape}')\n",
        "print(f'Testing dataset shape, X: {test_X.shape}')\n",
        "print(f'Testing dataset shape, y: {test_y.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train and Test on candidates classifiers\n",
        "\n",
        "For each candidate:\n",
        "\n",
        "    - create 25 classifiers\n",
        "    - train each classifier on the training set\n",
        "    - test each classifier on the testing set\n",
        "    - evaluate performance by each scorer\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Ron\\anaconda3\\envs\\PULearn\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'top_20': 4, 'top_100': 23, 'auprc': 0.1467609170061578}\n",
            "{'top_20': 4, 'top_100': 25, 'auprc': 0.14649288583694797}\n",
            "{'top_20': 4, 'top_100': 23, 'auprc': 0.1523085946934784}\n",
            "{'top_20': 5, 'top_100': 22, 'auprc': 0.14439058668724583}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.14939435901255493}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.1446309576107267}\n",
            "{'top_20': 3, 'top_100': 22, 'auprc': 0.13369941947132075}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.14939435901255493}\n",
            "{'top_20': 4, 'top_100': 25, 'auprc': 0.14086384928188}\n",
            "{'top_20': 4, 'top_100': 24, 'auprc': 0.13138542152154328}\n",
            "{'top_20': 5, 'top_100': 22, 'auprc': 0.14260019525125486}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.14360098994253534}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.1511268254873056}\n",
            "{'top_20': 4, 'top_100': 21, 'auprc': 0.15504787468752576}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.1511268254873056}\n",
            "{'top_20': 5, 'top_100': 26, 'auprc': 0.1477469012862166}\n",
            "{'top_20': 4, 'top_100': 24, 'auprc': 0.1552663959948345}\n",
            "{'top_20': 4, 'top_100': 25, 'auprc': 0.1550983794350185}\n",
            "{'top_20': 3, 'top_100': 22, 'auprc': 0.1610545619132294}\n",
            "{'top_20': 4, 'top_100': 24, 'auprc': 0.16670586171194965}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.1478607389393677}\n",
            "{'top_20': 4, 'top_100': 25, 'auprc': 0.15120445546061495}\n",
            "{'top_20': 5, 'top_100': 23, 'auprc': 0.1446309576107267}\n",
            "{'top_20': 5, 'top_100': 20, 'auprc': 0.14619976393332063}\n",
            "{'top_20': 3, 'top_100': 22, 'auprc': 0.1610545619132294}\n"
          ]
        }
      ],
      "source": [
        "models_name = 'models_rf_1_' + os.path.splitext(dataset_filename)[0]\n",
        "\n",
        "models = []\n",
        "\n",
        "for random_state in random_states:\n",
        "    base_clf = DecisionTreeClassifier(max_depth=10, max_leaf_nodes=120, min_samples_leaf=2, min_samples_split=2)\n",
        "    clf = BaggingPuClassifier(n_estimators =200, max_samples= 600, base_estimator=base_clf, n_jobs = -1, random_state= random_state, verbose=0)\n",
        "    scaler = StandardScaler()\n",
        "    model = Pipeline([\n",
        "                    (\"scale\", scaler),\n",
        "                    (\"clf\", clf)\n",
        "                    ])\n",
        "    models.append(model)\n",
        "\n",
        "evaluate_models(models, models_name, train_X, train_y, test_X, test_y, scorers_with_args, eval_models_path, eval_results_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Retrieve samples prediction (top_20) from models for inspection\n",
        "\n",
        "Inspecting:\n",
        "- validate the number of predictions, it should be 3242 (total size of testing set)\n",
        "- validate the number of predictions, it should be 71 (total size of positive in testing set)\n",
        "- share the prediction to domain expert to check if those predictions are sensible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_models_files = 'models_rf_1_dataset_p_4_q_1_dim_128_walkleng_100_numwalks_500_seed_37.pickle'\n",
        "\n",
        "with open(os.path.join(eval_models_path, sample_models_files), 'rb') as f:\n",
        "        models_rf_1 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "testing_set_samples_model = []\n",
        "testing_set_samples_model_top_20_mask = []\n",
        "\n",
        "num_sample = 3\n",
        "\n",
        "for i in range(num_sample):\n",
        "    y_pred = models[i].predict_proba(test_X)[:,1]\n",
        "    testing_set_samples_model.append(y_pred)\n",
        "    testing_set_samples_model_top_20_mask.append(topk(test_y, y_pred, top_k=20, get_mask=True))\n",
        "    \n",
        "id_series = dataset.iloc[test_X.index].id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_check_model_test_X_pred_proba = pd.DataFrame()\n",
        "sample_check_model_test_X_pred_proba['id'] = id_series\n",
        "sample_check_model_test_X_pred_proba['y'] = test_y\n",
        "for i in range(num_sample):\n",
        "    sample_check_model_test_X_pred_proba[f'models_sample_{i}_predict_proba'] = testing_set_samples_model[i]\n",
        "    sample_check_model_test_X_pred_proba[f'models_sample_{i}_top_20_mask'] = testing_set_samples_model_top_20_mask[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>y</th>\n",
              "      <th>models_sample_0_predict_proba</th>\n",
              "      <th>models_sample_0_top_20_mask</th>\n",
              "      <th>models_sample_1_predict_proba</th>\n",
              "      <th>models_sample_1_top_20_mask</th>\n",
              "      <th>models_sample_2_predict_proba</th>\n",
              "      <th>models_sample_2_top_20_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14643</th>\n",
              "      <td>ENSG00000007376</td>\n",
              "      <td>0</td>\n",
              "      <td>0.239069</td>\n",
              "      <td>False</td>\n",
              "      <td>0.260347</td>\n",
              "      <td>False</td>\n",
              "      <td>0.278986</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10150</th>\n",
              "      <td>ENSG00000169435</td>\n",
              "      <td>0</td>\n",
              "      <td>0.238978</td>\n",
              "      <td>False</td>\n",
              "      <td>0.321041</td>\n",
              "      <td>False</td>\n",
              "      <td>0.305130</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12511</th>\n",
              "      <td>ENSG00000139697</td>\n",
              "      <td>0</td>\n",
              "      <td>0.224801</td>\n",
              "      <td>False</td>\n",
              "      <td>0.236090</td>\n",
              "      <td>False</td>\n",
              "      <td>0.227781</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13381</th>\n",
              "      <td>ENSG00000137200</td>\n",
              "      <td>0</td>\n",
              "      <td>0.259852</td>\n",
              "      <td>False</td>\n",
              "      <td>0.217297</td>\n",
              "      <td>False</td>\n",
              "      <td>0.244288</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4313</th>\n",
              "      <td>ENSG00000143862</td>\n",
              "      <td>0</td>\n",
              "      <td>0.394807</td>\n",
              "      <td>False</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>False</td>\n",
              "      <td>0.453552</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2771</th>\n",
              "      <td>ENSG00000123570</td>\n",
              "      <td>0</td>\n",
              "      <td>0.235161</td>\n",
              "      <td>False</td>\n",
              "      <td>0.213337</td>\n",
              "      <td>False</td>\n",
              "      <td>0.234353</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1616</th>\n",
              "      <td>ENSG00000174417</td>\n",
              "      <td>0</td>\n",
              "      <td>0.389891</td>\n",
              "      <td>False</td>\n",
              "      <td>0.339054</td>\n",
              "      <td>False</td>\n",
              "      <td>0.361821</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7011</th>\n",
              "      <td>ENSG00000134882</td>\n",
              "      <td>1</td>\n",
              "      <td>0.274495</td>\n",
              "      <td>False</td>\n",
              "      <td>0.250580</td>\n",
              "      <td>False</td>\n",
              "      <td>0.206287</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7009</th>\n",
              "      <td>ENSG00000174917</td>\n",
              "      <td>0</td>\n",
              "      <td>0.254025</td>\n",
              "      <td>False</td>\n",
              "      <td>0.290461</td>\n",
              "      <td>False</td>\n",
              "      <td>0.284509</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4009</th>\n",
              "      <td>ENSG00000137267</td>\n",
              "      <td>0</td>\n",
              "      <td>0.196269</td>\n",
              "      <td>False</td>\n",
              "      <td>0.178852</td>\n",
              "      <td>False</td>\n",
              "      <td>0.218258</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3242 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id  y  models_sample_0_predict_proba  \\\n",
              "14643  ENSG00000007376  0                       0.239069   \n",
              "10150  ENSG00000169435  0                       0.238978   \n",
              "12511  ENSG00000139697  0                       0.224801   \n",
              "13381  ENSG00000137200  0                       0.259852   \n",
              "4313   ENSG00000143862  0                       0.394807   \n",
              "...                ... ..                            ...   \n",
              "2771   ENSG00000123570  0                       0.235161   \n",
              "1616   ENSG00000174417  0                       0.389891   \n",
              "7011   ENSG00000134882  1                       0.274495   \n",
              "7009   ENSG00000174917  0                       0.254025   \n",
              "4009   ENSG00000137267  0                       0.196269   \n",
              "\n",
              "       models_sample_0_top_20_mask  models_sample_1_predict_proba  \\\n",
              "14643                        False                       0.260347   \n",
              "10150                        False                       0.321041   \n",
              "12511                        False                       0.236090   \n",
              "13381                        False                       0.217297   \n",
              "4313                         False                       0.407500   \n",
              "...                            ...                            ...   \n",
              "2771                         False                       0.213337   \n",
              "1616                         False                       0.339054   \n",
              "7011                         False                       0.250580   \n",
              "7009                         False                       0.290461   \n",
              "4009                         False                       0.178852   \n",
              "\n",
              "       models_sample_1_top_20_mask  models_sample_2_predict_proba  \\\n",
              "14643                        False                       0.278986   \n",
              "10150                        False                       0.305130   \n",
              "12511                        False                       0.227781   \n",
              "13381                        False                       0.244288   \n",
              "4313                         False                       0.453552   \n",
              "...                            ...                            ...   \n",
              "2771                         False                       0.234353   \n",
              "1616                         False                       0.361821   \n",
              "7011                         False                       0.206287   \n",
              "7009                         False                       0.284509   \n",
              "4009                         False                       0.218258   \n",
              "\n",
              "       models_sample_2_top_20_mask  \n",
              "14643                        False  \n",
              "10150                        False  \n",
              "12511                        False  \n",
              "13381                        False  \n",
              "4313                         False  \n",
              "...                            ...  \n",
              "2771                         False  \n",
              "1616                         False  \n",
              "7011                         False  \n",
              "7009                         False  \n",
              "4009                         False  \n",
              "\n",
              "[3242 rows x 8 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_check_model_test_X_pred_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_check_model_test_X_pred_proba.to_csv(os.path.join('inspection', 'top20_samples_' + os.path.splitext(sample_models_files)[0] + '.csv'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
